{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from IoU_implementation import intersection_over_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLoss(nn.Module):\n",
    "    def __init__(self,S=7,B=2,C=20):\n",
    "        super(YoloLoss,self).__init__()\n",
    "        self.mse = nn.MSELoss(reduction=\"sum\")\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.lambda_noobj = 0.5\n",
    "        self.lambda_coord = 5\n",
    "\n",
    "    def forward(self,predictions,target):\n",
    "\n",
    "        # predictions/target shape = (batch_size, 7, 7, 30)\n",
    "        predictions = predictions.reshape(-1,self.S,self.S,self.C+self.B*5)\n",
    "\n",
    "        # send x,y,w,h for 1st bbox\n",
    "        # returns (batch_size,7,7,1)\n",
    "        iou_b1 = intersection_over_union(predictions[...,21:25],target[...,21:25])\n",
    " \n",
    "        # send x,y,w,h for 2nd bbox\n",
    "        # returns (batch_size,7,7,1)\n",
    "        iou_b2 = intersection_over_union(predictions[...,26:30],target[...,26:30])\n",
    "\n",
    "        # iou_b1.unsqueeze(0) adds an extra dimension at the beginning,\n",
    "        #  making its shape [1, batch_size, 7,7,1]\n",
    "        # same happens for iou_b2.unsqueeze(0) \n",
    "        # torch.cat([...], dim=0) concatenates these tensors along the new dimension,\n",
    "        # resulting in ious having shape [2, batch_size,7,7,1]\n",
    "        ious = torch.cat([iou_b1.unsqueeze(0),iou_b2.unsqueeze(0)],dim=0)\n",
    "\n",
    "        # torch.max(ious, dim=0) returns:\n",
    "        # compares values along 0th dimension and returns max value\n",
    "        # indices/bestboxes of those max value\n",
    "        # output will be [batch_size,7,7,1] for both\n",
    "\n",
    "        # EXAMPLE:\n",
    "        # ious = torch.tensor(\n",
    "        #     [\n",
    "        #         [\n",
    "        #             [0.5, 0.3],\n",
    "        #             [0.4, 0.8]\n",
    "        #         ],\n",
    "        #         [\n",
    "        #             [0.7, 0.2],\n",
    "        #             [0.6, 0.4]\n",
    "        #         ]\n",
    "        #     ])\n",
    "        # iou_maxes, bestbox = torch.max(ious, dim=0)\n",
    "        # will give : \n",
    "\n",
    "        # Maximum IOUs:\n",
    "        # tensor([[0.7, 0.3],\n",
    "        #         [0.6, 0.8]])\n",
    "\n",
    "        # Best bounding box indices:\n",
    "        # tensor([[1, 0],\n",
    "        #         [1, 0]])\n",
    "        # In summary, get the best bboxes of the 2 bboxes for each cell\n",
    "        # result: [2,batch_size,7,7,1] -> [batch_size,7,7,1]\n",
    "        iou_maxes, bestbox = torch.max(ious,dim=0)\n",
    "\n",
    "        # (d1, d2, d3, d4,...,d30) -> (d1, d2, d3, 1 , d4,...,d29)\n",
    "        # selects 21st element along the last dimension\n",
    "        exist_box = target[...,20].unsqueeze(3) # Iobji / Identity Object as described in YOLO paper\n",
    "\n",
    "        # FOR BOX COORDINATES\n",
    "        box_predictions = exist_box * (\n",
    "\n",
    "            (\n",
    "                bestbox * predictions[...,26:30] + (1-bestbox) * predictions[...,21:25]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        box_targets = exist_box * target[...,21:25]\n",
    "        box_predictions[...,2:4] = torch.sign(box_predictions[...,2:4]) * torch.sqrt(torch.abs(box_predictions[...,2:4] + 1e-6 ))\n",
    "\n",
    "        box_targets[...,2:4] = torch.sqrt(box_targets[...,2:4])\n",
    "\n",
    "        # (N,S,S,4) -> (N*S*S,4)\n",
    "        box_loss = self.mse(\n",
    "                    torch.flatten(box_predictions,end_dim=-2),\n",
    "                    torch.flatten(box_targets,end_dim=-2)\n",
    "        )\n",
    "\n",
    "        # FOR OBJECT LOSS\n",
    "        pred_box = (\n",
    "            bestbox * predictions[...,25:26] + (1-bestbox) * predictions[...,20:21]\n",
    "        )\n",
    "\n",
    "        # (N*S*S,1)\n",
    "        object_loss = self.mse(\n",
    "            torch.flatten(exist_box * pred_box),\n",
    "            torch.flatten(exist_box * target[...,20:21]),\n",
    "        )\n",
    "\n",
    "        # FOR NO OBJECT LOSS\n",
    "\n",
    "        # (N,S,S,1) -> (N,S*S)\n",
    "        no_object_loss = self.mse(\n",
    "            torch.flatten((1-exist_box)*predictions[...,20:21],start_dim=1),\n",
    "            torch.flatten((1-exist_box)*target[...,20:21],start_dim=1),\n",
    "        )\n",
    "\n",
    "        no_object_loss += self.mse(\n",
    "            torch.flatten((1-exist_box)*predictions[...,25:26],start_dim=1),\n",
    "            torch.flatten((1-exist_box)*target[...,20:21],start_dim=1),\n",
    "        )\n",
    "\n",
    "        # FOR CLASS LOSS\n",
    "        class_loss = self.mse(\n",
    "            torch.flatten(exist_box*predictions[...,:20],end_dim=-2),\n",
    "            torch.flatten(exist_box*target[...,:20],end_dim=-2),\n",
    "        )\n",
    "\n",
    "        loss = (\n",
    "            self.lambda_coord * box_loss\n",
    "            + object_loss\n",
    "            + self.lambda_noobj * no_object_loss\n",
    "            + class_loss\n",
    "        )\n",
    "\n",
    "        return loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
